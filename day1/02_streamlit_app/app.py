# app.py
import streamlit as st
import ui                   # UIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import llm                  # LLMãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import database             # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import metrics              # è©•ä¾¡æŒ‡æ¨™ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import data                 # ãƒ‡ãƒ¼ã‚¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import torch
from transformers import pipeline
from config import MODEL_NAME
from huggingface_hub import HfFolder
import traceback # ã‚¨ãƒ©ãƒ¼è©³ç´°è¡¨ç¤ºç”¨ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š ---
st.set_page_config(
    page_title="Gemma 2 Chatbot",
    page_icon="ðŸ¤–",  # <<< å¤‰æ›´ç‚¹: çµµæ–‡å­—ã‚¢ã‚¤ã‚³ãƒ³ã‚’è¿½åŠ 
    layout="wide",
    initial_sidebar_state="expanded" # <<< å¤‰æ›´ç‚¹: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’æœ€åˆã‹ã‚‰é–‹ã
)

# --- åˆæœŸåŒ–å‡¦ç† ---
# NLTKãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›žèµ·å‹•æ™‚ãªã©ï¼‰
try:
    metrics.initialize_nltk()
except Exception as e:
    st.warning(f"NLTKãƒ‡ãƒ¼ã‚¿ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", icon="âš ï¸")

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
try:
    database.init_db()
except Exception as e:
    st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", icon="ðŸš¨")
    st.stop() # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å¤±æ•—æ™‚ã¯ã‚¢ãƒ—ãƒªã‚’åœæ­¢

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒç©ºãªã‚‰ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥
try:
    data.ensure_initial_data()
except Exception as e:
    st.warning(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æŠ•å…¥ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", icon="âš ï¸")


# --- LLMãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰ ---
# ãƒ¢ãƒ‡ãƒ«ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦å†åˆ©ç”¨
@st.cache_resource(show_spinner="ðŸ¤– Gemmaãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...") # <<< å¤‰æ›´ç‚¹: ã‚¹ãƒ”ãƒŠãƒ¼è¡¨ç¤ºã‚’è¿½åŠ 
def load_model_cached():
    """LLMãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        # HuggingFace Hubã¸ã®ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã‚’ç¢ºèª (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
        # token = HfFolder.get_token()
        # if not token:
        #     st.warning("Hugging Face Hubã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ã¾ã›ã‚“ã€‚ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚", icon="ðŸ”’")

        pipe = pipeline(
            "text-generation",
            model=MODEL_NAME,
            model_kwargs={"torch_dtype": torch.bfloat16},
            device=device,
            # token=token # å¿…è¦ã«å¿œã˜ã¦ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¸¡ã™
        )
        # <<< å¤‰æ›´ç‚¹: æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ st.success ã§è¡¨ç¤ºã—ã€ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚‚åŠ ãˆã‚‹
        st.success(f"ãƒ¢ãƒ‡ãƒ« '{MODEL_NAME}' ã®èª­ã¿è¾¼ã¿å®Œäº† (ãƒ‡ãƒã‚¤ã‚¹: {device})", icon="âœ…")
        return pipe
    except ImportError as e:
         st.error(f"å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}", icon="ðŸš¨")
         st.info("`pip install torch transformers accelerate bitsandbytes` ãªã©ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
         return None
    except Exception as e:
        # <<< å¤‰æ›´ç‚¹: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ st.error ã§è¡¨ç¤ºã—ã€å…·ä½“çš„ãªåŽŸå› ã‚’ç¤ºå”†
        st.error(f"ãƒ¢ãƒ‡ãƒ« '{MODEL_NAME}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚", icon="ðŸš¨")
        st.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")
        st.warning("GPUãƒ¡ãƒ¢ãƒªä¸è¶³ã€ãƒ¢ãƒ‡ãƒ«åã®èª¤ã‚Šã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æŽ¥ç¶šã€HuggingFace Hubã®èªè¨¼ãªã©ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚", icon="ðŸ’¡")
        # traceback.print_exc() # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è©³ç´°ãªã‚¨ãƒ©ãƒ¼ã‚’å‡ºåŠ›ã™ã‚‹å ´åˆ
        return None

# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ
pipe = load_model_cached()

# --- Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ---

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
# <<< å¤‰æ›´ç‚¹: `with st.sidebar:` ã‚’ä½¿ã†ã¨ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã§è¦‹ã‚„ã™ããªã‚‹
with st.sidebar:
    st.title("ðŸ“„ ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
    st.divider() # <<< å¤‰æ›´ç‚¹: åŒºåˆ‡ã‚Šç·šã‚’è¿½åŠ 

    # ãƒšãƒ¼ã‚¸é¸æŠžæ–¹æ³•ã®æ”¹å–„ (ã‚¢ã‚¤ã‚³ãƒ³è¿½åŠ )
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ä½¿ç”¨ã—ã¦é¸æŠžãƒšãƒ¼ã‚¸ã‚’ä¿æŒ
    if 'page' not in st.session_state:
        st.session_state.page = "ãƒãƒ£ãƒƒãƒˆ" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒšãƒ¼ã‚¸

    # <<< å¤‰æ›´ç‚¹: ãƒšãƒ¼ã‚¸é¸æŠžè‚¢ã«ã‚¢ã‚¤ã‚³ãƒ³ã‚’è¿½åŠ 
    pages = {
        "ãƒãƒ£ãƒƒãƒˆ": "ðŸ’¬",
        "å±¥æ­´é–²è¦§": "ðŸ“œ",
        "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†": "ðŸ“Š"
    }
    page_options = list(pages.keys())

    # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    try:
        current_page_index = page_options.index(st.session_state.page)
    except ValueError:
        current_page_index = 0 # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ(ãƒãƒ£ãƒƒãƒˆ)
        st.session_state.page = page_options[0]

    # ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§ãƒšãƒ¼ã‚¸é¸æŠž
    selected_page = st.radio(
        "ãƒšãƒ¼ã‚¸ã‚’é¸æŠž", # ãƒ©ãƒ™ãƒ«ã‚’å°‘ã—å¤‰æ›´
        options=page_options,
        format_func=lambda page: f"{pages[page]} {page}", # ã‚¢ã‚¤ã‚³ãƒ³ã¨ãƒšãƒ¼ã‚¸åã‚’è¡¨ç¤º
        index=current_page_index,
        key="page_selector",
        label_visibility="collapsed", # <<< å¤‰æ›´ç‚¹: ãƒ©ãƒ™ãƒ« "ãƒšãƒ¼ã‚¸ã‚’é¸æŠž" ã‚’éžè¡¨ç¤ºã«ã—ã€ã‚¢ã‚¤ã‚³ãƒ³ä»˜ãé¸æŠžè‚¢ã‚’å¼·èª¿
    )

    # é¸æŠžã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«åæ˜  (st.radio ã®ã‚­ãƒ¼æ›´æ–°ã«ä¾å­˜)
    # on_change ã‚„ st.rerun() ã¯å¿…é ˆã§ã¯ãªã„ã“ã¨ãŒå¤šã„ãŒã€è¤‡é›‘ãªçŠ¶æ…‹ç®¡ç†ãŒå¿…è¦ãªå ´åˆã«ä½¿ã†
    if selected_page != st.session_state.page:
        st.session_state.page = selected_page
        st.rerun() # ãƒšãƒ¼ã‚¸é·ç§»ã‚’å³æ™‚åæ˜ 

    st.divider() # <<< å¤‰æ›´ç‚¹: åŒºåˆ‡ã‚Šç·šã‚’è¿½åŠ 

    # <<< å¤‰æ›´ç‚¹: ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹è¡¨ç¤ºã‚’è¿½åŠ 
    if pipe:
        st.success("âœ… ãƒ¢ãƒ‡ãƒ«æº–å‚™å®Œäº†", icon="ðŸ‘")
    else:
        st.error("âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—", icon="ðŸ˜¥")

    st.divider() # <<< å¤‰æ›´ç‚¹: åŒºåˆ‡ã‚Šç·šã‚’è¿½åŠ 

    # <<< å¤‰æ›´ç‚¹: é–‹ç™ºè€…æƒ…å ±ã«ã‚¢ã‚¤ã‚³ãƒ³ã‚’è¿½åŠ 
    st.info("ðŸ‘¨â€ðŸ’» é–‹ç™ºè€…: [Suwa Haruya]", icon="â„¹ï¸")
    # st.image("your_logo.png", use_column_width=True) # ãƒ­ã‚´ç”»åƒãªã©ã‚’è¡¨ç¤ºã™ã‚‹å ´åˆ


# --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
# <<< å¤‰æ›´ç‚¹: ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã§è¦‹ãŸç›®ã‚’èª¿æ•´
st.title("ðŸ¤– Gemma 2 Chatbot with Feedback")
st.caption("âœ¨ Gemmaãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚å›žç­”ã¸ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã§ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™ï¼")
st.divider() # <<< å¤‰æ›´ç‚¹: ã‚¿ã‚¤ãƒˆãƒ«ä¸‹ã®åŒºåˆ‡ã‚Šç·š

# <<< å¤‰æ›´ç‚¹: ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é ˜åŸŸã‚’ã‚³ãƒ³ãƒ†ãƒŠã§å›²ã‚€ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã ãŒæ§‹é€ åŒ–ã—ã‚„ã™ã„)
main_container = st.container()

with main_container:
    if st.session_state.page == "ãƒãƒ£ãƒƒãƒˆ":
        # <<< å¤‰æ›´ç‚¹: å„ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ st.header ã‚„ st.subheader ã§æ˜Žç¢ºåŒ–
        st.header("ðŸ’¬ ãƒãƒ£ãƒƒãƒˆ", divider="rainbow") # dividerã§è¦‹å‡ºã—ã‚’è£…é£¾
        if pipe:
            # ui.display_chat_page ã¯ ui.py ã§å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã¨ä»®å®š
            ui.display_chat_page(pipe)
        else:
            st.error("ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚’åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚", icon="ðŸš«")
            st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ã¾ãŸã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚", icon="ðŸ‘€")

    elif st.session_state.page == "å±¥æ­´é–²è¦§":
        st.header("ðŸ“œ å±¥æ­´é–²è¦§", divider="rainbow")
        # ui.display_history_page ã¯ ui.py ã§å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã¨ä»®å®š
        ui.display_history_page()

    elif st.session_state.page == "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†":
        st.header("ðŸ“Š ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†", divider="rainbow")
        # ui.display_data_page ã¯ ui.py ã§å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã¨ä»®å®š
        ui.display_data_page()

# --- ãƒ•ãƒƒã‚¿ãƒ¼ãªã©ï¼ˆä»»æ„ï¼‰ ---
st.divider()
st.caption("Â© 2025 Gemma Chatbot")